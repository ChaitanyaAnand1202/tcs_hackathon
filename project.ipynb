{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHTks2YcS4SaPsedHiCnj0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChaitanyaAnand1202/tcs_hackathon/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MchQ2Xm2Lyca"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # AI-Powered Insurance Policy Information Chatbot\n",
        "#\n",
        "# This notebook implements an insurance policy information chatbot that can answer questions about different types of insurance policies using a knowledge base and LLM capabilities.\n",
        "\n",
        "# %%\n",
        "!pip install -q langchain openai faiss-cpu pypdf tiktoken gradio\n",
        "\n",
        "# %%\n",
        "import os\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "import gradio as gr\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 1: Set Up Knowledge Base\n",
        "#\n",
        "# We'll create a knowledge base from insurance policy PDFs. For this demo, you would replace these with your actual insurance policy documents.\n",
        "\n",
        "# %%\n",
        "# Upload your insurance policy PDFs to Colab first\n",
        "# Here we'll use sample paths - replace with your actual files\n",
        "policy_files = [\n",
        "    \"health_insurance.pdf\",\n",
        "    \"auto_insurance.pdf\",\n",
        "    \"life_insurance.pdf\",\n",
        "    \"home_insurance.pdf\"\n",
        "]\n",
        "\n",
        "# In a real scenario, you would upload your PDFs to Colab or use a cloud storage\n",
        "# For this demo, we'll proceed assuming the files are available\n",
        "\n",
        "# %%\n",
        "def create_knowledge_base(pdf_paths):\n",
        "    \"\"\"Create a vector database from insurance policy PDFs\"\"\"\n",
        "    documents = []\n",
        "    for pdf_path in pdf_paths:\n",
        "        try:\n",
        "            loader = PyPDFLoader(pdf_path)\n",
        "            documents.extend(loader.load())\n",
        "        except Exception as e:\n",
        "            print(f\"Could not load {pdf_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    if not documents:\n",
        "        raise ValueError(\"No documents were loaded. Please check your PDF files.\")\n",
        "\n",
        "    # Split documents into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    db = FAISS.from_documents(texts, embeddings)\n",
        "\n",
        "    return db\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 2: Initialize the Chatbot System\n",
        "\n",
        "# %%\n",
        "def initialize_chatbot(openai_api_key):\n",
        "    \"\"\"Initialize the chatbot with knowledge base and LLM\"\"\"\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "    # Create knowledge base (in a real scenario, you might want to pre-create this)\n",
        "    try:\n",
        "        db = create_knowledge_base(policy_files)\n",
        "    except ValueError as e:\n",
        "        print(f\"Knowledge base creation failed: {e}\")\n",
        "        # Fallback to a simple LLM without knowledge base\n",
        "        return OpenAI(temperature=0)\n",
        "\n",
        "    # Create retriever chain\n",
        "    retriever = db.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=OpenAI(temperature=0),\n",
        "        chain_type=\"stuff\",\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True\n",
        "    )\n",
        "\n",
        "    return qa\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 3: Chatbot Response Generation\n",
        "\n",
        "# %%\n",
        "def generate_response(query, chat_history, qa_system):\n",
        "    \"\"\"Generate a response to user query using the QA system\"\"\"\n",
        "    try:\n",
        "        # Get response from QA system\n",
        "        result = qa_system({\"query\": query})\n",
        "        answer = result[\"result\"]\n",
        "\n",
        "        # Include source documents for reference\n",
        "        sources = \"\\n\\nSources:\\n\" + \"\\n\".join(\n",
        "            [f\"- {doc.metadata['source']} (page {doc.metadata.get('page', 'N/A')})\"\n",
        "             for doc in result[\"source_documents\"]]\n",
        "        )\n",
        "\n",
        "        full_response = answer + sources\n",
        "\n",
        "        # Fallback mechanism if answer is not confident\n",
        "        if \"I don't know\" in answer or \"not provided in the context\" in answer:\n",
        "            full_response += \"\\n\\nI couldn't find a complete answer in our documents. Would you like me to connect you with a human agent for further assistance?\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating response: {e}\")\n",
        "        full_response = \"I encountered an error processing your request. Please try again or contact our customer support.\"\n",
        "\n",
        "    chat_history.append((query, full_response))\n",
        "    return chat_history, chat_history\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 4: User Interface with Gradio\n",
        "\n",
        "# %%\n",
        "def create_chatbot_interface(openai_api_key):\n",
        "    \"\"\"Create the Gradio interface for the chatbot\"\"\"\n",
        "    qa_system = initialize_chatbot(openai_api_key)\n",
        "\n",
        "    with gr.Blocks(title=\"Insurance Policy Chatbot\", theme=gr.themes.Soft()) as demo:\n",
        "        gr.Markdown(\"\"\"\n",
        "        # Insurance Policy Information Chatbot\n",
        "        Welcome to our AI-powered insurance assistant. Ask me anything about our policies, coverage options, premiums, or claims processes.\n",
        "        \"\"\")\n",
        "\n",
        "        chatbot = gr.Chatbot(label=\"Chat History\", height=500)\n",
        "        msg = gr.Textbox(label=\"Your Question\", placeholder=\"Type your question about insurance policies here...\")\n",
        "        clear = gr.Button(\"Clear Chat\")\n",
        "\n",
        "        def respond(message, chat_history):\n",
        "            chat_history, _ = generate_response(message, chat_history, qa_system)\n",
        "            return \"\", chat_history\n",
        "\n",
        "        msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
        "        clear.click(lambda: None, None, chatbot, queue=False)\n",
        "\n",
        "    return demo\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Step 5: Run the Chatbot\n",
        "#\n",
        "# To run this chatbot:\n",
        "# 1. Upload your insurance policy PDFs to Colab\n",
        "# 2. Enter your OpenAI API key\n",
        "# 3. Launch the interface\n",
        "\n",
        "# %%\n",
        "# For security, in a real scenario you would use environment variables or secrets\n",
        "# This is just for demo purposes\n",
        "OPENAI_API_KEY = \"your-api-key-here\"  # Replace with your actual API key\n",
        "\n",
        "# Create and launch the interface\n",
        "if OPENAI_API_KEY != \"your-api-key-here\":\n",
        "    demo = create_chatbot_interface(OPENAI_API_KEY)\n",
        "    demo.launch(share=True)\n",
        "else:\n",
        "    print(\"Please enter your OpenAI API key to proceed.\")\n",
        "\n",
        "# %% [markdown]\n",
        "# ## Methodology and Approach\n",
        "#\n",
        "# ### Why This Approach Was Selected:\n",
        "#\n",
        "# 1. *Knowledge Base Integration*:\n",
        "#    - Using PDFs as the knowledge base allows easy updating of policy information\n",
        "#    - FAISS vector store enables efficient similarity search for relevant policy information\n",
        "#\n",
        "# 2. *LLM for Natural Language Processing*:\n",
        "#    - OpenAI's LLM provides strong language understanding capabilities\n",
        "#    - RetrievalQA chain combines document retrieval with LLM processing for accurate answers\n",
        "#\n",
        "# 3. *Fallback Mechanism*:\n",
        "#    - The system detects when it can't answer confidently and offers human escalation\n",
        "#    - Error handling ensures graceful degradation\n",
        "#\n",
        "# 4. *User Interface*:\n",
        "#    - Gradio provides a simple, clean interface that can be embedded in websites/apps\n",
        "#    - Chat history maintains context for better user experience\n",
        "#\n",
        "# ### Implementation Notes:\n",
        "#\n",
        "# - In a production environment, you would:\n",
        "#   - Store the vector database persistently rather than recreating it each time\n",
        "#   - Use proper API key management (not hardcoded)\n",
        "#   - Add more sophisticated conversation management\n",
        "#   - Include user authentication if needed\n",
        "#   - Add more insurance-specific features (premium calculators, etc.)\n",
        "#\n",
        "# - The current implementation focuses on the core functionality while demonstrating all key requirements."
      ]
    }
  ]
}